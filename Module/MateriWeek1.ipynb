{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10c25d6f",
   "metadata": {},
   "source": [
    "# Hands-On Pertemuan 1: Pengenalan Big Data dan Overview Teknologi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7117dfdb",
   "metadata": {},
   "source": [
    "## Tujuan\n",
    "Pada akhir praktikum ini, mahasiswa diharapkan mampu:\n",
    "1. Memahami konsep dasar Big Data.\n",
    "2. Menjelaskan karakteristik dan tantangan Big Data (Volume, Variety, Velocity, dan Veracity).\n",
    "3. Mengenal teknologi yang digunakan dalam ekosistem Big Data.\n",
    "4. Menginstal dan mengonfigurasi Anaconda untuk bekerja dengan alat Big Data seperti Hadoop dan Spark.\n",
    "5. Memulai praktik sederhana terkait pengolahan data menggunakan PySpark dan Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e805141",
   "metadata": {},
   "source": [
    "## Peralatan yang Dibutuhkan\n",
    "1. Anaconda (untuk manajemen lingkungan)\n",
    "2. Jupyter Notebook (bawaan dari Anaconda)\n",
    "3. PySpark (untuk pemrosesan data skala besar)\n",
    "4. Pandas (untuk data analysis)\n",
    "5. Python (bawaan dari Anaconda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daa78a0",
   "metadata": {},
   "source": [
    "## Langkah-Langkah Hands-On"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b963c0",
   "metadata": {},
   "source": [
    "### 1. Instalasi Anaconda\n",
    "- **Langkah 1: Unduh dan Instal Anaconda**\n",
    "  Anaconda adalah platform distribusi Python yang menyertakan berbagai alat pengembangan, termasuk Jupyter Notebook. Ikuti langkah-langkah instalasi sesuai sistem operasi:\n",
    "  - Unduh Anaconda: [Download Anaconda](https://www.anaconda.com/products/individual)\n",
    "  - Instal sesuai instruksi yang ada di situs web tersebut (Windows/Mac/Linux).\n",
    "\n",
    "- **Langkah 2: Menginstal PySpark di Anaconda**\n",
    "  Setelah Anaconda terinstal, tambahkan PySpark:\n",
    "  ```bash\n",
    "  conda install -c conda-forge pyspark\n",
    "  ```\n",
    "\n",
    "- **Langkah 3: Menginstal Pandas**\n",
    "  Untuk memudahkan data analysis, install Pandas:\n",
    "  ```bash\n",
    "  conda install pandas\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208f1a45",
   "metadata": {},
   "source": [
    "### 2. Pengenalan dan Praktik Dasar PySpark dan Pandas\n",
    "- **Langkah 1: Membuka Jupyter Notebook**\n",
    "  Setelah instalasi selesai, buka Jupyter Notebook melalui Anaconda Navigator atau melalui terminal dengan perintah:\n",
    "  ```bash\n",
    "  jupyter notebook\n",
    "  ```\n",
    "\n",
    "- **Langkah 2: Membuat Project Notebook Baru**\n",
    "  Di Jupyter Notebook, buat notebook baru untuk praktikum ini.\n",
    "\n",
    "- **Langkah 3: Praktik dengan PySpark**\n",
    "  Buat program sederhana untuk memulai dengan PySpark. Gunakan PySpark untuk membuat DataFrame dan memanipulasi data sederhana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78a5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Memulai Spark session\n",
    "spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()\n",
    "\n",
    "# Membuat DataFrame sederhana\n",
    "data = [(\"Ali\", 34), (\"Budi\", 23), (\"Citra\", 29), (\"Dina\", 45)]\n",
    "columns = [\"Nama\", \"Usia\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Menampilkan DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8747276f",
   "metadata": {},
   "source": [
    "- **Tugas 1**: Jalankan kode di atas dan buat modifikasi dengan menambahkan data lain berupa kolom pekerjaan, hobi dan gender."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f84a333",
   "metadata": {},
   "source": [
    "### 3. Praktik PySpark Lanjutan\n",
    "- **Latihan 1**: Memanipulasi Data dengan PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f391ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Memulai Spark session\n",
    "spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()\n",
    "\n",
    "# Membuat DataFrame sederhana\n",
    "data = [(\"Ali\", 34), (\"Budi\", 23), (\"Citra\", 29), (\"Dina\", 45)]\n",
    "columns = [\"Nama\", \"Usia\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Menampilkan DataFrame\n",
    "df.show()\n",
    "\n",
    "# Filtering data\n",
    "df_filtered = df.filter(df['Usia'] > 30)\n",
    "df_filtered.show()\n",
    "\n",
    "# Menghitung rata-rata usia\n",
    "from pyspark.sql.functions import avg\n",
    "df.groupBy().agg(avg(\"Usia\")).show()\n",
    "\n",
    "# Mengurutkan data berdasarkan usia\n",
    "df_sorted = df.orderBy(\"Usia\", ascending=False)\n",
    "df_sorted.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06767bc",
   "metadata": {},
   "source": [
    "- **Tugas 2**: Lakukan filter, penghitungan rata-rata, dan pengurutan data menggunakan PySpark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e34a5",
   "metadata": {},
   "source": [
    "### 4. Praktik dengan Pandas\n",
    "- **Latihan 2**:  Buat DataFrame menggunakan Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1f2ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Membuat DataFrame Pandas\n",
    "data_pandas = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Usia\": [34, 23, 29, 45]}\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# Menampilkan DataFrame Pandas\n",
    "df_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da455f1",
   "metadata": {},
   "source": [
    "- **Tugas 3**: Modifikasi DataFrame Pandas dengan menambahkan kolom baru dan melakukan operasi seperti filtering data berdasarkan usia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0042b2b",
   "metadata": {},
   "source": [
    "### 5. Praktik Pandas Lanjutan\n",
    "- **Latihan 3**: Penggunaan Pandas untuk operasi lebih kompleks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a8142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Membuat DataFrame Pandas\n",
    "data_pandas = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Usia\": [34, 23, 29, 45]}\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# Membuat DataFrame kedua\n",
    "data_pandas_2 = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Pekerjaan\": [\"Dokter\", \"Guru\", \"Insinyur\", \"Perawat\"]}\n",
    "df_pandas_2 = pd.DataFrame(data_pandas_2)\n",
    "\n",
    "# Join antara dua DataFrame\n",
    "df_joined = pd.merge(df_pandas, df_pandas_2, on=\"Nama\")\n",
    "print(df_joined)\n",
    "\n",
    "# Menghitung statistik deskriptif\n",
    "print(df_pandas.describe())\n",
    "\n",
    "# Plotting Data\n",
    "import matplotlib.pyplot as plt\n",
    "df_pandas['Usia'].plot(kind='bar')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ed75d",
   "metadata": {},
   "source": [
    "- **Tugas 4**: Lakukan penggabungan DataFrame dan visualisasikan data dengan Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf671ba3",
   "metadata": {},
   "source": [
    "### 5. Menggabungkan PySpark dan Pandas\n",
    "- **Latihan 4: Mengonversi DataFrame antara PySpark dan Pandas**\n",
    "  Praktik untuk convert DataFrame dari PySpark ke Pandas dan sebaliknya:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337e123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengonversi DataFrame dari PySpark ke Pandas\n",
    "df_pandas_from_spark = df.toPandas()\n",
    "\n",
    "# Mengonversi DataFrame dari Pandas ke PySpark\n",
    "df_spark_from_pandas = spark.createDataFrame(df_pandas)\n",
    "\n",
    "# Menampilkan DataFrame hasil konversi\n",
    "df_pandas_from_spark, df_spark_from_pandas.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cba4e5c",
   "metadata": {},
   "source": [
    "- **Tugas 5**: Gunakan metode ini untuk menggabungkan data yang Anda buat di PySpark dengan data dari Pandas, kemudian lakukan analisis sederhana seperti menghitung rata-rata usia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdba6be",
   "metadata": {},
   "source": [
    "### 6. Konversi Data antara PySpark dan Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f863defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengonversi DataFrame dari PySpark ke Pandas\n",
    "df_pandas_from_spark = df.toPandas()\n",
    "\n",
    "# Mengonversi DataFrame dari Pandas ke PySpark\n",
    "df_spark_from_pandas = spark.createDataFrame(df_pandas)\n",
    "\n",
    "# Menampilkan DataFrame hasil konversi\n",
    "df_pandas_from_spark, df_spark_from_pandas.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65adbe71",
   "metadata": {},
   "source": [
    "- **Tugas 6**: Gabungkan data dari PySpark dan Pandas, lalu lakukan operasi statistik seperti menghitung nilai maksimum usia."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
