{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+------+------+\n",
      "| Name|Age|Gender|Salary|DeptId|\n",
      "+-----+---+------+------+------+\n",
      "|James| 34|     M|  3000|     1|\n",
      "| Anna| 28|     F|  4100|     2|\n",
      "|  Lee| 23|     M|  2700|     1|\n",
      "+-----+---+------+------+------+\n",
      "\n",
      "+----+---+\n",
      "|Name|Age|\n",
      "+----+---+\n",
      "|Anna| 28|\n",
      "+----+---+\n",
      "\n",
      "+------------------+\n",
      "|       avg(Salary)|\n",
      "+------------------+\n",
      "|3266.6666666666665|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tugas 1\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('EmployeeAnalysis').getOrCreate()\n",
    "\n",
    "data = [\n",
    "    ('James', 34, 'M', 3000, 1),\n",
    "    ('Anna', 28, 'F', 4100, 2),\n",
    "    ('Lee', 23, 'M', 2700, 1)\n",
    "]\n",
    "columns = ['Name', 'Age', 'Gender', 'Salary', 'DeptId']\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "df.createOrReplaceTempView('employees')\n",
    "spark.sql('SELECT * FROM employees').show()\n",
    "spark.sql('SELECT Name, Age FROM employees WHERE Salary > 3000').show()\n",
    "spark.sql('SELECT AVG(Salary) FROM employees').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---+\n",
      "|Gender|TotalSalary|Age|\n",
      "+------+-----------+---+\n",
      "|     M|       2700| 23|\n",
      "|     F|       4100| 28|\n",
      "|     M|       3000| 34|\n",
      "+------+-----------+---+\n",
      "\n",
      "+------+-------------+\n",
      "|DeptId|AverageSalary|\n",
      "+------+-------------+\n",
      "|     1|       2850.0|\n",
      "|     2|       4100.0|\n",
      "+------+-------------+\n",
      "\n",
      "+-----+---+------+------+------+\n",
      "| Name|Age|Gender|Salary|DeptId|\n",
      "+-----+---+------+------+------+\n",
      "|James| 34|     M|  3000|     1|\n",
      "+-----+---+------+------+------+\n",
      "\n",
      "+-----+---+------+------+------+----------+\n",
      "| Name|Age|Gender|Salary|DeptId|SalaryRank|\n",
      "+-----+---+------+------+------+----------+\n",
      "|James| 34|     M|  3000|     1|         1|\n",
      "|  Lee| 23|     M|  2700|     1|         2|\n",
      "| Anna| 28|     F|  4100|     2|         1|\n",
      "+-----+---+------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tugas 2\n",
    "spark.sql('SELECT Gender, SUM(Salary) as TotalSalary, Age FROM employees GROUP BY Gender, Age ORDER BY Age').show()\n",
    "\n",
    "# Menghitung rata-rata gaji per departemen\n",
    "spark.sql('SELECT DeptId, AVG(Salary) AS AverageSalary FROM employees GROUP BY DeptId').show()\n",
    "\n",
    "# Menghitung rata-rata gaji per gender\n",
    "avg_salary_gender = spark.sql('SELECT Gender, AVG(Salary) AS AvgSalary FROM employees GROUP BY Gender')\n",
    "avg_salary_gender.createOrReplaceTempView('avg_gender')\n",
    "\n",
    "# Mencari karyawan dengan gaji di atas rata-rata per gender\n",
    "spark.sql('''\n",
    "    SELECT e.*\n",
    "    FROM employees e\n",
    "    JOIN avg_gender ag ON e.Gender = ag.Gender\n",
    "    WHERE e.Salary > ag.AvgSalary\n",
    "''').show()\n",
    "\n",
    "# Membuat ranking karyawan berdasarkan gaji dalam departemen\n",
    "spark.sql('''\n",
    "    SELECT *,\n",
    "           DENSE_RANK() OVER (PARTITION BY DeptId ORDER BY Salary DESC) AS SalaryRank\n",
    "    FROM employees\n",
    "''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+----+\n",
      "| Name|Age|Salary|rank|\n",
      "+-----+---+------+----+\n",
      "|  Lee| 23|  2700|   1|\n",
      "| Anna| 28|  4100|   1|\n",
      "|James| 34|  3000|   1|\n",
      "+-----+---+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Menggunakan window functions untuk menemukan top 3 karyawan dalam setiap kelompok usia\n",
    "spark.sql('''\n",
    "    SELECT Name, Age, Salary, \n",
    "           ROW_NUMBER() OVER (PARTITION BY Age ORDER BY Salary DESC) as rank\n",
    "    FROM employees\n",
    "''').createOrReplaceTempView('ranked_employees')\n",
    "\n",
    "# Mengambil karyawan dengan rank 1 sampai 3\n",
    "spark.sql('''\n",
    "    SELECT Name, Age, Salary, rank\n",
    "    FROM ranked_employees\n",
    "    WHERE rank <= 3\n",
    "''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/24 11:14:26 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "[Stage 43:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---------+-----------+\n",
      "| Name|Age| DeptName|ProjectName|\n",
      "+-----+---+---------+-----------+\n",
      "|  Lee| 23|       HR|  Project A|\n",
      "|James| 34|       HR|  Project A|\n",
      "| Anna| 28|Marketing|  Project B|\n",
      "+-----+---+---------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Pertemuan9').getOrCreate()\n",
    "\n",
    "# Data setup for complex SQL queries\n",
    "employees = spark.createDataFrame([\n",
    "    ('James', 34, 'M', 3000, 1),\n",
    "    ('Anna', 28, 'F', 4100, 2),\n",
    "    ('Lee', 23, 'M', 2700, 1)\n",
    "], ['Name', 'Age', 'Gender', 'Salary', 'DeptId'])\n",
    "departments = spark.createDataFrame([\n",
    "    (1, 'HR'),\n",
    "    (2, 'Marketing')\n",
    "], ['DeptId', 'DeptName'])\n",
    "projects = spark.createDataFrame([\n",
    "    (1, 'Project A'),\n",
    "    (2, 'Project B')\n",
    "], ['DeptId', 'ProjectName'])\n",
    "employees.createOrReplaceTempView('employees')\n",
    "departments.createOrReplaceTempView('departments')\n",
    "projects.createOrReplaceTempView('projects')\n",
    "\n",
    "# Complex SQL query involving multiple joins and subqueries\n",
    "spark.sql('''\n",
    "SELECT e.Name, e.Age, d.DeptName, p.ProjectName\n",
    "FROM employees e\n",
    "JOIN departments d ON e.DeptId = d.DeptId\n",
    "JOIN projects p ON e.DeptId = p.DeptId\n",
    "''').show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
